1. - Difference between collections and stream?
| Feature          | **Collections**                                                                 | **Streams**                                                                                                  |
| ---------------- | ------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------ |
| **Definition**   | Data structure that stores **elements in memory** (e.g., `List`, `Set`, `Map`). | A **pipeline of data** (sequence of elements) supporting functional-style operations.                        |
| **Nature**       | **Eager** â€“ you store and access elements directly.                             | **Lazy** â€“ operations are executed only when a terminal operation (like `collect()`, `forEach()`) is called. |
| **Storage**      | Actually **stores data** (in memory).                                           | Does **not store data**; it computes results from a source (collection, array, I/O channel).                 |
| **Traversal**    | Can be traversed **multiple times**.                                            | A stream can be traversed **only once** (after a terminal operation, itâ€™s consumed).                         |
| **Modification** | You can **add/remove/update** elements.                                         | Streams are **read-only** (cannot modify the underlying data).                                               |
| **Iteration**    | External iteration (e.g., `for-each` loop).                                     | Internal iteration (handled by stream API).                                                                  |
| **Parallelism**  | Manual (`for` loops, `ExecutorService`).                                        | Built-in (`parallelStream()`).                                                                               |
| **Operations**   | Focused on **data storage & structure manipulation**.                           | Focused on **data processing (map, filter, reduce, collect)**.                                               |

âœ… Interview-Ready Answer
Collections are about storing and managing data in memory, while Streams are about processing data in a functional, declarative way.
Collections use external iteration and allow modifications, while Streams use internal iteration, are lazy, can be parallelized easily, and are consumed only once.

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------

2. - Internal Working of HashMap, HashSet, TreeMap and TreeSet and ConcurrentHashMap?

ğŸ”¹ 1. HashMap (Keyâ€“Value Pair Storage)
Data Structure: Uses array of buckets internally (each bucket is a linked list / tree in Java 8+).
How it works:
When you put a key-value pair (put(key, value)), the hashCode() of the key is computed.
The hash is converted to an index (bucket position).
If the bucket is empty â†’ insert directly.
If not empty â†’ compare using equals() to avoid duplicates.

Before Java 8: bucket is a LinkedList.
Java 8+: If collisions become large (>8 elements), LinkedList is converted to a balanced tree (Red-Black Tree).
On get(key) â†’ same hash process to find the bucket â†’ scan list/tree for match using equals().
Key Points:
Allows 1 null key, multiple null values.
Order is not guaranteed.
Time complexity: O(1) avg, O(log n) in case of tree bucket.

ğŸ”¹ 2. HashSet
Built on top of HashMap.
Working:
When you do set.add(x), internally it calls map.put(x, PRESENT), where PRESENT is a dummy constant object.
Duplicate check is handled by HashMapâ€™s containsKey().
Key Points:
Stores only unique elements.
Allows 1 null element.
Order is not guaranteed.

ğŸ”¹ 3. TreeMap (Sorted Keyâ€“Value Map)
Data Structure: Red-Black Tree (Self-balancing BST).
How it works:
Keys are sorted according to their natural order (via Comparable) or using a Comparator.
Insertions and lookups walk down the tree and maintain balance (via color-flipping & rotations).
Key Points:
Does not allow null key (throws NullPointerException), but values can be null.
Order is sorted (ascending by default).
Time complexity: O(log n) for put/get.

ğŸ”¹ 4. TreeSet
Built on top of TreeMap.
Working:
When you do set.add(x), internally it calls map.put(x, PRESENT).
Sorting order maintained via TreeMapâ€™s Red-Black Tree.
Key Points:
Stores unique elements in sorted order.
Does not allow null element (from Java 7 onwards if using natural ordering).
Time complexity: O(log n) for add, remove, contains.

ğŸ”¹ 5. ConcurrentHashMap
Thread-safe version of HashMap.
How it works (Java 8):
Data is stored in an array of Nodes (similar to HashMap).
Instead of locking the entire map, it uses fine-grained locking:
Before Java 8: Segmented locking (each segment = smaller HashMap with a lock).
Java 8+: Uses CAS (Compare-And-Swap) + synchronized blocks on buckets only when needed.
Read operations (get) are non-blocking (almost O(1)).
Write operations (put, remove) lock only the affected bucket.
Key Points:
No null key or null value allowed.
Faster than Hashtable and Collections.synchronizedMap().
Suitable for concurrent environments.

ğŸ–¼ï¸ Quick Analogy

HashMap â†’ A big cupboard with labeled boxes (fast lookup, unordered).
HashSet â†’ Just the labels of the cupboard, no values inside.
TreeMap â†’ Cupboard where keys are always arranged in sorted order.
TreeSet â†’ Just the sorted labels of the cupboard.
ConcurrentHashMap â†’ A cupboard with multiple workers,each worker locks only a single box instead of locking the whole cupboard.

âš¡ Interview Tip:
If asked "Why does ConcurrentHashMap not allow null key/value?" â†’
ğŸ‘‰ Because in multi-threaded environments, a null return from get(key) would create ambiguity:
Did the mapping not exist?
Or was the value actually null?

why treemap doesnt allow null keys?
âœ… Why TreeMap doesnâ€™t allow null keys
TreeMap uses Red-Black Tree internally
Keys are stored in sorted order.
Sorting is done either by:
Natural ordering (Comparable), or
A Comparator you provide.

Comparison Problem
When inserting a new key, TreeMap must compare it with existing keys (compareTo() or compare()).
If the key is null â†’ calling null.compareTo(something) causes NullPointerException.
Example:
TreeMap<String, Integer> map = new TreeMap<>();
map.put(null, 1);  // NPE at runtime
Design Choice (Clarity)
HashMap can allow one null key because it doesnâ€™t sort â€” it just hashes it.
TreeMap must always maintain order, so null key would break the comparison logic.
To keep things consistent and predictable, Java designers decided: no null keys in TreeMap.
âœ… Why null values are allowed in TreeMap
TreeMap compares keys, not values.
So values can be null safely.
ğŸ¯ Interview-ready Answer
TreeMap does not allow null keys because it sorts keys using compareTo() or a Comparator, and comparing null with other keys would throw NullPointerException.
On the other hand, HashMap allows one null key since hashing does not require comparisons.

| Collection Type        | Null Key Allowed?                    | Null Value Allowed?          | Notes                                                                      |
| ---------------------- | ------------------------------------ | ---------------------------- | -------------------------------------------------------------------------- |
| **HashMap**            | âœ… Yes (only **1** null key)          | âœ… Yes (multiple null values) | Stores key-value pairs in buckets (hashing).                               |
| **HashSet**            | âœ… Yes (only **1** null element)      | N/A                          | Built on top of `HashMap`, so 1 null element allowed.                      |
| **TreeMap**            | âŒ No (throws `NullPointerException`) | âœ… Yes                        | Keys must be comparable â†’ `null` breaks comparison.                        |
| **TreeSet**            | âŒ No (throws `NullPointerException`) | N/A                          | Built on top of `TreeMap`, so no null elements.                            |
| **ConcurrentHashMap**  | âŒ No                                 | âŒ No                         | Disallows null key & values to avoid ambiguity in concurrent environments. |
| **Hashtable** (legacy) | âŒ No                                 | âŒ No                         | Thread-safe, but stricter rules than `HashMap`.                            |

--------------------------------------------------------------------------------------------

what does it mean by concurrent environment?
A concurrent environment is when multiple threads are executing at the same time and may
try to access or modify shared resources (like variables, objects, or collections).

In single-threaded code â†’ only one thread runs at a time, so no conflicts.

In multi-threaded / concurrent code â†’ two or more threads may read/write the same data simultaneously,
which can lead to race conditions, data corruption, or inconsistent state.
One thread might be writing to the bucket, another thread reading from the same bucket.
This can lead to inconsistent state, lost updates, or infinite loops (in HashMap before Java 8).

âœ… Why ConcurrentHashMap is needed
A normal HashMap is not thread-safe â†’ fails in concurrent environments.
ConcurrentHashMap is designed for concurrency:
Multiple threads can safely read without blocking.
Write operations lock only the specific bucket (not the whole map).
Prevents corruption in concurrent scenarios.

-------------------------------------------------------------------------------------

How ConcurrentHashMap avoids locking the entire map (i.e., bucket-level locking with CAS) in a visual way for interviews?
ğŸ”¹ How ConcurrentHashMap avoids locking the entire map
âœ… Old way (Hashtable / SynchronizedMap)
Every read/write was wrapped with a synchronized block.
So if 1 thread was updating a value, all other threads were blocked â€” even for simple reads.
This caused huge performance bottlenecks in concurrent environments.

âœ… New way (ConcurrentHashMap in Java 8+)
Does not lock the whole map.
Uses fine-grained locking + CAS (Compare-And-Swap)
ğŸ”¸ Internal Structure
Data stored as Node[] table (like HashMap).
Each bucket (index in the table) can have:
A Node (key, value, next)
Or a TreeNode (red-black tree) when collisions are high

ğŸ”¸ Operations
Reads (get)
Completely lock-free.
Just compute hash, go to bucket, and traverse linked list/tree.
Uses volatile fields so threads see the latest values.
âœ… Multiple threads can read simultaneously â†’ very fast.

Writes (put, remove)
Only lock the specific bucket (bin) being updated.
Done using synchronized on Node level (not entire map).
Steps:
Compute hash â†’ find bucket index.
If bucket empty â†’ try to insert using CAS (no locking needed).
If bucket occupied â†’ synchronize only that bucket â†’ insert/update.
âœ… Other buckets remain free for other threads.
Resizing (rehashing)
Even resizing is parallelized.
Multiple threads help redistribute buckets into the new table.

ğŸ–¼ï¸ Visual Analogy
Imagine a cupboard with many drawers (buckets):
Hashtable â†’ Only 1 key ğŸ—ï¸ for the entire cupboard â†’ if one person is using it, others must wait.
ConcurrentHashMap â†’ Every drawer has its own small lock ğŸ”’ â†’ multiple people can use different drawers at the same time.

ğŸ¯ Interview-ready Summary
ConcurrentHashMap achieves thread safety without locking the entire map by using bucket-level locking and CAS operations.
Reads are completely lock-free.
Writes only lock the specific bucket being updated.
This allows multiple threads to work in parallel, making it much faster than Hashtable or Collections.synchronizedMap() in concurrent environments.

âš¡ Bonus: If asked â€œWhy CAS?â€ â†’
ğŸ‘‰ CAS (Compare-And-Swap) is a non-blocking atomic operation that updates a value only if it has not changed by another thread.
This avoids heavy locking and improves concurrency.
ğŸ¯ How this connects to ConcurrentHashMap CHM
Instead of locking entire structure, CHM uses CAS for some operations (like inserting in an empty bucket).
If CAS succeeds â†’ update happens without locking.
If CAS fails â†’ falls back to bucket-level synchronization.
So CAS is the first line of defense, and fine-grained locking is the backup.
ğŸ”¹ What CAS actually does
Imagine you have a box that stores a number.
You think the number is X.
You want to change it to Y.
But before you do, you check: â€œIs the box still X?â€
If yes â†’ update it to Y. âœ…
If no â†’ do nothing. âŒ
That is Compare-And-Swap
It is an atomic CPU instruction that ensures only one threadâ€™s update succeeds when multiple threads try at the same time.

AtomicInteger count = new AtomicInteger(0);
// Thread 1
count.compareAndSet(0, 1); // "If value is 0, set to 1"
Hereâ€™s what happens internally:
Thread 1 sees value = 0.
It compares 0 with expected 0. âœ… Match!
Swaps value â†’ 1.

// Thread 2
count.compareAndSet(0, 2); // "If value is 0, set to 2"
Thread 2 thinks value is still 0.
But after Thread 1, the value is actually 1. âŒ
Compare fails â†’ Thread 2â€™s update is rejected.
So only one thread wins, without using a lock.

ğŸ”¹ Why is this useful?
In a concurrent environment.
Many threads may want to update the same variable.
Instead of blocking each other with synchronized, CAS lets threads try updates in parallel.
Only the thread that finds the â€œexpected valueâ€ succeeds.

ğŸ”¸ Visual Analogy
Think of CAS like putting your name on a form:
You say: â€œIf the form is still blank, Iâ€™ll write my name.â€
If someone else already wrote their name, your attempt fails.
No fighting, no waiting â€” just check and update in one step.

ğŸ‘‰ So in short: CAS = check current value â†’ if it matches what I expect, update it atomically. Else, fail.

Example:- RaceConditionCASFix.java

---------------------------------------------------------------------------------------------------------

ğŸ”¹ What is ConcurrentModificationException?
Itâ€™s a runtime exception that occurs when a collection (like ArrayList, HashMap, etc.) is structurally modified while being iterated,
using an iterator or enhanced-for loop.
Structural modification â†’ adding/removing elements that change the size of the collection.
Safe modification â†’ only through the iteratorâ€™s own remove() method.

ğŸ”¹ Why does this happen?
Most collection classes (like ArrayList, HashMap) are fail-fast.
When you create an iterator, it keeps an internal modCount (modification count).
Every structural modification updates modCount
If during iteration, iterator detects modCount has changed unexpectedly â†’ it throws ConcurrentModificationException.

ğŸ”¹ How to avoid CME?
âœ… Use iteratorâ€™s remove() method
âœ… Use CopyOnWriteArrayList (thread-safe, avoids CME)
ğŸ”¹ In Multi-threading Context
CME also occurs if:
One thread is iterating a collection,
Another thread modifies it at the same time.
Thatâ€™s why we use ConcurrentHashMap, CopyOnWriteArrayList, etc. in concurrent environments.

âœ… Interview One-Liner:
ConcurrentModificationException happens because most collections are fail-fast â€”
if the collection is structurally modified outside the iterator, iteration is no longer safe, so Java throws this exception to prevent unpredictable behavior.

ğŸ”¹ Why does list.remove(s) sometimes work without exception?
The enhanced-for loop is syntax sugar for using an Iterator.
for (String s : list) { ... }
becomes
Iterator<String> it = list.iterator();
while (it.hasNext()) {
    String s = it.next();
    ...
}
When you call list.remove(s) directly, it modifies the list but not the iteratorâ€™s internal state.
The next call to it.next() checks the modCount mismatch â†’ only then CME is thrown.

ğŸ”¹ Cases
Case 1: Single removal, then loop ends
If you remove the last element being iterated (or remove once and iteration finishes before it.next() is called again), you might not see CME.
Case 2: More iterations after removal.
If iteration continues, the next it.next() will detect modCount mismatch â†’ CME.

âœ… One-liner for interview:
list.remove(s) inside a loop may or may not throw ConcurrentModificationException immediately â€”
the exception is thrown only when the iterator detects a modCount mismatch on the next iteration step.

-----------------------------------------------------------------------------------------

- Which Data structure to use for frequent data update, remove data and add new data & searching?
ğŸ”¹ Requirements
Frequent updates
Frequent additions

Frequent removals
Efficient searching
So we want fast insert, delete, and search.

ğŸ”¹ Data Structure Options
1. Array / ArrayList
âœ… Fast random access (O(1) by index).
âŒ Insertion/deletion in the middle is costly (O(n)) because of shifting.
âŒ Not ideal for frequent add/remove.

2. LinkedList
âœ… Fast insertion/deletion (O(1) if node reference known).
âŒ Searching is slow (O(n)).
âŒ Not good if search is frequent.

3. HashMap / HashSet
âœ… Average O(1) for insert, delete, update, search by key.
âœ… Best when search is based on a key (hashable).
âŒ No ordering of elements.
âŒ Worst-case O(n) if hash collisions happen (though rare with good hash).
ğŸ‘‰ Best choice when you need frequent add/remove/search with keys.

4. TreeMap / TreeSet (Balanced BST like Red-Black Tree)
âœ… O(log n) for insert, delete, search.
âœ… Maintains sorted order.
âŒ Slower than HashMap for pure key lookups.
ğŸ‘‰ Best choice when you need sorted data + frequent updates.

5. ConcurrentHashMap
âœ… Like HashMap but thread-safe.
âœ… Ideal in concurrent environments.

6. Hybrid Approach
Sometimes we combine:
HashMap + LinkedList â†’ LRU Cache (fast lookup + ordered eviction).
HashMap + Tree â†’ fast lookups + ordered iteration.

ğŸ”¹ Final Answer (for interviews)
If you need fastest add/remove/update/search â†’ HashMap / HashSet (average O(1)).
If you also need sorted order â†’ TreeMap / TreeSet (O(log n)).
If operations happen in multi-threaded environment â†’ ConcurrentHashMap.

âœ… One-liner to say in interview:
â€œFor frequent insert, delete, update, and search,
a HashMap (or ConcurrentHashMap in multi-threaded context) is best because it provides average O(1) performance for these operations.
If ordering is required, then a TreeMap is more suitable, with O(log n) operations.â€

ğŸ”¹ Comparison of Common Data Structures in Java

| Data Structure        | Search (by value)        | Insert                            | Delete                            | Update          | Ordered?            | Notes                                                      |
| --------------------- | ------------------------ | --------------------------------- | --------------------------------- | --------------- | ------------------- | ---------------------------------------------------------- |
| **Array / ArrayList** | `O(n)` (linear search)   | `O(1)` at end, `O(n)` in middle   | `O(n)` (shift needed)             | `O(1)` by index | âœ… (insertion order) | Great for random access, bad for frequent updates/removals |
| **LinkedList**        | `O(n)`                   | `O(1)` if node known, else `O(n)` | `O(1)` if node known, else `O(n)` | `O(n)`          | âœ… (insertion order) | Good for sequential access, poor for search                |
| **HashMap / HashSet** | `O(1)` avg, `O(n)` worst | `O(1)` avg                        | `O(1)` avg                        | `O(1)` avg      | âŒ (unordered)       | Best for frequent add/remove/search by key                 |
| **TreeMap / TreeSet** | `O(log n)`               | `O(log n)`                        | `O(log n)`                        | `O(log n)`      | âœ… (sorted order)    | Good balance when you need sorted + efficient ops          |
| **ConcurrentHashMap** | `O(1)` avg               | `O(1)` avg                        | `O(1)` avg                        | `O(1)` avg      | âŒ                   | Thread-safe, used in concurrent environments               |

ğŸ”¹ Interview-ready Answer
ğŸ‘‰ If interviewer asks â€œWhich DS for frequent add/remove/update/search?â€
Say:
HashMap â€” Best choice, O(1) avg for all operations.
ConcurrentHashMap â€” If multi-threaded.
TreeMap â€” If sorted order is required.

ğŸ”¹ Real-world Use Cases
1. HashMap â†’ Fast Lookup (O(1))
ğŸ‘‰ Example: LRU Cache (Least Recently Used Cache)
Used in browsers, databases, OS page replacement.
We want:
Fast lookup (O(1)) â†’ HashMap.
Maintain usage order â†’ Doubly LinkedList.
Implementation:
HashMap stores <key, node> references.
Doubly LinkedList keeps track of order (move recently used to front, evict least used from back).
ğŸ“Œ This is exactly how LinkedHashMap in Java can be used to implement LRU Cache.

2. TreeMap â†’ Sorted Data
ğŸ‘‰ Example: Leaderboard / Ranking System (e.g., gaming platform, coding contest scoreboard)
You need:
Fast insert/update scores.
Keep scores sorted.
TreeMap stores <score, player> entries in sorted order.
Allows O(log n) search for top N scores.

3. ConcurrentHashMap â†’ Thread-safe Lookups
ğŸ‘‰ Example: Real-time Session Store (e.g., web server sessions, API rate-limiting)
Multiple threads update sessions.
HashMap is not thread-safe (may corrupt data).
ConcurrentHashMap allows concurrent reads/writes with bucket-level locks + CAS

4. ArrayList â†’ Random Access
ğŸ‘‰ Example: Playlist in a Music App
Accessing by index â†’ O(1)
Insertion/removal rare compared to lookups.
ArrayList is ideal here.

5. LinkedList â†’ Frequent Insert/Delete
ğŸ‘‰ Example: Undo/Redo Stack (like in editors, IDEs)
Adding/removing from head/tail â†’ O(1).
LinkedList works better than ArrayList if size changes frequently.

--------------------------------------------------------------------------------------

1. What data structures are used in HashMap?
Data structures used inside HashMap (Java 8+)
Array (Bucket array)
The core structure is an array of Node<K,V>[].
Each index (called a bucket) is where entries are stored after hashing the key.
The bucket index = hash(key) % capacity.
Linked List (for collisions)
When multiple keys hash to the same bucket, they are chained together as a singly linked list (Node<K,V> objects).
Before Java 8 â†’ always linked list.
Balanced Tree (Red-Black Tree)
Since Java 8, if too many elements end up in the same bucket (default threshold â‰¥ 8 entries in a bucket), the linked list is converted into a Red-Black Tree.
Why? To reduce worst-case lookup from O(n) (linked list) â†’ O(log n) (tree).

Summary (Java 8+)
Array â†’ backbone, stores references to buckets.
Linked List â†’ handles collisions (when few).
Red-Black Tree â†’ replaces linked list when bucket grows large (â‰¥ 8 nodes).

HashMap (Java 8+)
 â””â”€â”€ Array of buckets
      â”œâ”€â”€ Bucket[0] â†’ Linked List (Node -> Node -> Node)
      â”œâ”€â”€ Bucket[1] â†’ Red-Black Tree (NodeA, NodeB...)
      â”œâ”€â”€ Bucket[2] â†’ null (empty)
      â””â”€â”€ ...

âš¡ In interviews, they often ask:
ğŸ‘‰ â€œWhy was Red-Black Tree introduced in HashMap?â€
Answer:
To avoid performance degradation to O(n) in case of hash collisions (e.g., if someone attacks with many keys having same hash).
Using a balanced tree gives O(log n) lookup in such cases.

-----------------------------------------------------------------------------------------------------------------------------------------------------

- HashMap in synchronized block vs ConcurrentHashMap?
1. HashMap inside a synchronized block
Default HashMap is not thread-safe.
If multiple threads modify it at the same time â†’ race conditions, data corruption, or even infinite loops (before Java 8, in resizing).
To make it thread-safe, you wrap critical sections with synchronized.

Map<String, String> map = new HashMap<>();

synchronized (map) {
    map.put("A", "Apple");
    map.put("B", "Banana");
}

ğŸ”¹ Characteristics
Synchronization is at the whole map level.
At any given time, only one thread can operate on the map (read/write).
This becomes a bottleneck under high concurrency.
Read operations are also blocked if a write is happening.

2. ConcurrentHashMap
Designed specifically for concurrent access.
Introduced in Java 5 (java.util.concurrent).
Internally uses:
Segmented buckets in Java 7 (locks per segment).
Bucket-level locks with CAS (compare-and-swap) in Java 8 (much finer granularity).
Allows multiple threads to read/write concurrently as long as they work on different buckets.
Example:
ConcurrentHashMap<String, String> cmap = new ConcurrentHashMap<>();
cmap.put("A", "Apple");
cmap.put("B", "Banana");
ğŸ”¹ Characteristics
Better performance under concurrency
Reads are non-blocking (no lock).
Writes only block the affected bucket, not the entire map.
Null keys/values not allowed (to avoid ambiguity in concurrent environments).

| Feature                    | HashMap + synchronized block   | ConcurrentHashMap                     |
| -------------------------- | ------------------------------ | ------------------------------------- |
| Thread Safety              | Yes (if synchronized manually) | Yes (built-in)                        |
| Lock granularity           | Entire map                     | Bucket-level (finer)                  |
| Performance in concurrency | Poor (bottleneck)              | High (scales well)                    |
| Null keys/values allowed?  | Yes                            | No                                    |
| Read operations            | Blocked if synchronized        | Non-blocking                          |
| Use case                   | Low concurrency, small apps    | High concurrency, multi-threaded apps |

--------------------------------------------------------------------------------------------------------------

- Stack and queue basics, how are they implemented?
StackLL.java
Stack (LIFO â€“ Last In, First Out)
Concept: The last element pushed is the first one to be popped.
Operations:
push(x) â†’ insert at top
pop() â†’ remove from top
peek() â†’ look at top without removing
Java provides java.util.Stack class (extends Vector).
But in modern Java, ArrayDeque is preferred because itâ€™s faster and doesnâ€™t have legacy Vector overhead.

âœ… Key Difference:
Stack (legacy) â†’ synchronized, slower, extends Vector.
ArrayDeque (modern) â†’ not synchronized, faster, recommended.

Queue (FIFO â€“ First In, First Out)
Concept: The first element inserted is the first one to be removed.
Operations:
enqueue(x) â†’ add at rear
dequeue() â†’ remove from front
peek() â†’ see front


| Feature  | Stack                           | Queue                           |
| -------- | ------------------------------- | ------------------------------- |
| Order    | LIFO (Last In First Out)        | FIFO (First In First Out)       |
| Use case | Undo, function calls, recursion | Scheduling, resource sharing    |
| Impl     | Array or Linked List            | Array (circular) or Linked List |
| Main ops | push, pop, peek                 | enqueue, dequeue, peek          |


ğŸ”¹ Stack (java.util.Stack)
Legacy class (since Java 1.0, extends Vector).
Thread-safe â†’ all methods are synchronized
Slower than ArrayDeque due to synchronization overhead.
Still works fine, but considered outdated for most use cases.
Use case:
If you really need a synchronized stack and donâ€™t want to manage locks.
Example: legacy systems where Stack is already in use.

ğŸ”¹ ArrayDeque (java.util.ArrayDeque)
Introduced in Java 1.6.
Not synchronized â†’ faster in single-threaded or controlled multithreaded contexts.
Implemented as a resizable circular array â†’ efficient push, pop, peek
Preferred for modern applications.
Use case:
If you need a stack in single-threaded or performance-critical code.
Example: parsing, DFS traversal, expression evaluation.

ğŸ”¹ What if I need thread safety with ArrayDeque?
You can wrap it:
Deque<Integer> stack = Collections.synchronizedDeque(new ArrayDeque<>());


| Feature        | Stack (Legacy)                 | ArrayDeque (Modern)                                    |
| -------------- | ------------------------------ | ------------------------------------------------------ |
| Thread-safety  | Yes (synchronized methods)     | No (but can wrap with `Collections.synchronizedDeque`) |
| Performance    | Slower (due to sync)           | Faster (no sync overhead)                              |
| Implementation | Extends `Vector` (array-based) | Resizable circular array                               |
| Recommended?   | âŒ Avoid for new code           | âœ… Preferred choice                                     |


Java has multiple built-in queue implementations in the java.util and java.util.concurrent packages.
ğŸ”¹ 1. Queue Interface (java.util.Queue)
Introduced in Java 1.5
Defines common queue operations:
offer(e) â†’ add element (returns false if full)
poll() â†’ remove and return head (null if empty)
peek() â†’ get head without removing (null if empty)

ğŸ”¹ 2. Common Queue Implementations :- QueueLL.java
âœ… LinkedList
Implements both Queue and Deque.
Doubly-linked list internally.
Can be used as FIFO queue or Deque (double-ended queue).

âœ… ArrayDeque
Resizable circular array.
Faster than LinkedList.
Implements Queue and Deque.
Cannot store null elements.

âœ… PriorityQueue
Elements are ordered according to natural ordering or a Comparator.
Not FIFO â†’ it gives you the smallest (or highest priority) element first.

ğŸ”¹ 3. Concurrent Queue Implementations (java.util.concurrent)
ConcurrentLinkedQueue â†’ lock-free, thread-safe queue (FIFO)
LinkedBlockingQueue â†’ thread-safe, used in producer-consumer.
ArrayBlockingQueue â†’ fixed-size, bounded queue.
PriorityBlockingQueue â†’ thread-safe version of PriorityQueue.
DelayQueue, SynchronousQueue â†’ advanced specialized queues

| Queue Type            | Backed By          | Ordered? | Thread-Safe? | Use Case                    |
| --------------------- | ------------------ | -------- | ------------ | --------------------------- |
| LinkedList            | Doubly linked list | FIFO     | âŒ            | General purpose             |
| ArrayDeque            | Circular array     | FIFO     | âŒ            | Faster than LinkedList      |
| PriorityQueue         | Heap               | Priority | âŒ            | Scheduling, priority tasks  |
| ConcurrentLinkedQueue | Linked nodes       | FIFO     | âœ…            | Non-blocking multi-threaded |
| LinkedBlockingQueue   | Linked list        | FIFO     | âœ…            | Producer-Consumer           |
| ArrayBlockingQueue    | Array (fixed size) | FIFO     | âœ…            | Bounded blocking queue      |

----------------------------------------------------------------------------------------------------------------


Q: ConcurrentLinkedQueue vs LinkedBlocking Queue vs ArrayBlocking Queue, and producer - consumer problem ?
ğŸ”¹ 1. ConcurrentLinkedQueue
Lock-free, thread-safe implementation of a queue.
Uses CAS (Compare-And-Swap) instead of locks â†’ very fast in high-concurrency.
Unbounded (can grow until memory runs out).
Non-blocking â†’ threads donâ€™t wait, just fail (offer() returns false if issue).

ğŸ”¹ 2. LinkedBlockingQueue
Thread-safe blocking queue backed by linked nodes.
Can be bounded or unbounded (default = Integer.MAX_VALUE).
Supports blocking operations
put() â†’ waits if full.
take() â†’ waits if empty.
Used a lot in Producer-Consumer problem.
ğŸ‘‰ Use when: multiple producers & consumers need to coordinate with blocking.

ğŸ”¹ 3. ArrayBlockingQueue
Thread-safe blocking queue backed by an array.
Fixed-size (bounded) â†’ capacity is set when created.
Also supports put() and take() (blocking)
Faster than LinkedBlockingQueue for predictable, bounded workloads.
ğŸ‘‰ Use when: you want a bounded queue with predictable performance.

-----------------------------------------------------------------------------

ğŸ”¹ Producer-Consumer Problem (Classic)
Definition:
One or more Producer threads create data and put it into a queue.
One or more Consumer threads take data from the queue and process it.
Problem: we must ensure synchronization so producers donâ€™t overwrite and consumers donâ€™t read empty queues.
e.g.,
ProducerConsumerDemo.java

| Queue Type            | Blocking? | Bounded?  | Backed By       | Use Case                             |
| --------------------- | --------- | --------- | --------------- | ------------------------------------ |
| ConcurrentLinkedQueue | âŒ         | Unbounded | CAS (lock-free) | High throughput, non-blocking        |
| LinkedBlockingQueue   | âœ…         | Optional  | Linked nodes    | Producer-consumer, unbounded/bounded |
| ArrayBlockingQueue    | âœ…         | âœ… Fixed   | Array           | Producer-consumer with fixed buffer  |

e.g., ProducerConsumerWaitNotify.java
ğŸ”¹ Key Points to Notice
synchronized â†’ ensures only one thread modifies the buffer at a time.
wait() â†’ releases the lock and makes the thread wait.
notify() â†’ wakes up one waiting thread (either producer or consumer).
while (condition) â†’ always check in a loop (to avoid spurious wakeups).
This is lower-level and harder to manage â†’ thatâ€™s why Java introduced BlockingQueue

| Approach              | Synchronization Mechanism | Easy to Implement?                   | Recommended Today?             |
| --------------------- | ------------------------- | ------------------------------------ | ------------------------------ |
| `wait()` + `notify()` | Manual monitor locks      | âŒ More boilerplate, risk of deadlock | âŒ Only for teaching/interviews |
| `BlockingQueue`       | Built-in blocking ops     | âœ… Very clean                         | âœ… Yes                          |


-------------------------------------------------------------------------------


Find duplicates in an array without hashset?
âš¡ Key Idea:
We used the array itself as a "visited marker" by flipping signs. If we ever try to visit an index that's already negative â†’ we found a duplicate.
| Approach             | Time       | Space | Notes                          |
| -------------------- | ---------- | ----- | ------------------------------ |
| Brute Force          | O(nÂ²)      | O(1)  | Bad for large input            |
| Sort & Compare       | O(n log n) | O(1)  | Loses original order           |
| Index Marking (Best) | O(n)       | O(1)  | Works if numbers in range 1..n |

What if we need the original array later?
Option 1: Restore â†’ After the pass, just flip all negatives back to positive.
Option 2: Work on a copy of the array instead.

---------------------------------------------------------------------------------------

- Find duplicate strings with latest Java features.
ğŸ”¹ Solution 1 â€“ Using Collectors.groupingBy
ğŸ”¹ Solution 2 â€“ Using Collections.frequency (simpler, but less efficient)
ğŸ”¹ Solution 3 â€“ Using Set trick with Streams

âœ¨ Interview Tip:
Solution 1 â†’ Best when you want counts + duplicates (scalable).
Solution 2 â†’ Short but O(nÂ²) (bad for large lists).
Solution 3 â†’ Simple + efficient O(n).

1ï¸âƒ£ Collections.frequency
What it does:
Counts how many times a given element appears in a collection (List, etc).
So when finding duplicates:
You can filter all elements whose Collections.frequency(list, element) > 1.

2ï¸âƒ£ Collectors.groupingBy
What it does:
Groups elements of a stream into a Map according to a key function.

ğŸ’¡ Summary:
Collections.frequency â†’ Easy to use, good for small lists, O(nÂ²) for duplicates
Collectors.groupingBy â†’ Powerful for large lists + also gives counts, O(n).

frequencyMap.entrySet().stream()
Converts the Map into a stream of Map.Entry objects.
Each entry has a key (the string) and a value (the count).
Example for {"apple"=2, "banana"=1} â†’ entries:
Map.Entry("apple", 2)
Map.Entry("banana", 1)

filter(e -> e.getValue() > 1)
Keeps only entries where the value (count) is greater than 1.
After filtering, you get:
Map.Entry("apple", 2)

map(Map.Entry::getKey) âœ…
Transforms each Map.Entry into its key only.
Why? Because we only want the duplicate strings, not their counts.
So after mapping, the stream becomes:
"apple"

collect(Collectors.toSet())
Collects all keys (strings) into a Set â†’ ["apple"].
Collectors.counting() is a built-in collector in Java Streams.
It counts the number of elements in a stream.
Returns a Long.

------------------------------------------------------------------------------

25/11/2025

Q: 6. difference between copyOnWriteArrayList and arrayList?
ğŸš€ CopyOnWriteArrayList (COWAL)
CopyOnWriteArrayList is a thread-safe variant of ArrayList where all mutating operations (add, set, remove)
 create a new copy of the underlying array.

âœ… Why is it special?
âœ” Thread-safe without using locks for reading
Reads happen on a separate immutable snapshot.
So reads are very fast and never blocked.
âœ” Ideal for scenarios where:
Many reads
Very few writes
Example: event listeners, routing tables, configs.

âš™ï¸ How it works internally?
Whenever you call add(), remove(), or set():
It creates a copy of the array
Updates the new array
Replaces the reference
So write operations are slow and costly, but safe.

Key point:
Even if another thread modifies the list during iteration,
the iterator does NOT throw ConcurrentModificationException.

| Feature            | CopyOnWriteArrayList   | ArrayList   | Vector                  |
| ------------------ | ---------------------- | ----------- | ----------------------- |
| Thread-safe        | âœ” Yes                  | âŒ No        | âœ” Yes (synchronized)    |
| Read performance   | â­ Very Fast            | Fast        | Slow                    |
| Write performance  | âŒ Slow (copies array)  | Fast        | Slow                    |
| Fail-safe iterator | âœ” Yes                  | âŒ No        | âŒ No                    |
| Use Case           | Many reads, few writes | Normal list | Legacy thread-safe list |

âš ï¸ Disadvantages
High memory usage â†’ every write creates a new array
Not suitable for frequent updates
Expensive for large lists

â­ When to use?
Use CopyOnWriteArrayList when:
âœ” You have 95% reads and 5% writes
âœ” You want safe iteration without locks
âœ” You cannot afford ConcurrentModificationException
âœ” You need thread-safe but fast reads

âœ… 1. Reads in COWAL are lock-free
CopyOnWriteArrayList uses a volatile reference to an internal immutable array.
All read operations (get(), iteration) directly read the volatile array, without any lock
No synchronization â†’ No thread blocking â†’ Extremely fast and scalable under concurrency.
âœ” Readers never wait
Even if multiple threads are reading simultaneously, reads are:
lock-free
non-blocking
wait-free

âŒ 2. Reads in ArrayList (multi-threaded) require external locking
ArrayList itself is not thread-safe.
If multiple threads read concurrently without synchronization, itâ€™s unsafe.
So in real multi-threaded scenarios, you must add locking:
synchronized (list) {
    list.get(i);
}
Or use Collections.synchronizedList(), which also locks on each read.
â—This locking slows down reads significantly.

==================================================================================


